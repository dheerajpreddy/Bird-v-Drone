{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "8986f7cf-611d-4134-857e-1d4ec7ec7479",
    "_execution_state": "idle",
    "_uuid": "d83f34d78b635e92a9cc0a90bdb661ee87fe4c23"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "\n",
    "birds_dir = os.listdir('../dataset/birds/004.Groove_billed_Ani/')\n",
    "drones_dir = os.listdir('../dataset/actual/drones/')\n",
    "birds = []\n",
    "drones = []\n",
    "for i in range(35):\n",
    "    birds.append(cv2.resize(cv2.imread(\"../dataset/birds/004.Groove_billed_Ani/\" + birds_dir[i]), (200, 200)).flatten())\n",
    "    drones.append(cv2.resize(cv2.imread(\"../dataset/actual/drones/\" + drones_dir[i]), (200, 200)).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "img_data = np.concatenate((np.array(birds), np.array(drones)), axis=0)\n",
    "img_target = []\n",
    "for i in range(70):\n",
    "    if i<35:\n",
    "        img_target.append(0)\n",
    "    else:\n",
    "        img_target.append(1)\n",
    "img_target = np.array(img_target)\n",
    "print(img_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(img_data, img_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma='auto')\n",
    "#fit to the trainin data\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      1.00      0.56         7\n",
      "           1       0.00      0.00      0.00        11\n",
      "\n",
      "   micro avg       0.39      0.39      0.39        18\n",
      "   macro avg       0.19      0.50      0.28        18\n",
      "weighted avg       0.15      0.39      0.22        18\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[ 0 56]\n",
      " [ 0 44]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "9eba422657ea2ad8ab6c6e462d0ba213b3ebbd6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digits dataset keys \n",
      "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "# load the digits dataset\n",
    "digits = datasets.load_digits()\n",
    "print('Digits dataset keys \\n{}'.format(digits.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "c49c968e666b7c87345e43c22025796d2292546a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset target name: \n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "shape of datset: (1797, 64) \n",
      "and target: (1797,)\n",
      "shape of the images: (1797, 8, 8)\n"
     ]
    }
   ],
   "source": [
    "print('dataset target name: \\n{}'.format(digits.target_names))\n",
    "print('shape of datset: {} \\nand target: {}'.format(digits.data.shape, digits.target.shape))\n",
    "print('shape of the images: {}'.format(digits.images.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "63635d82e25d73d74a03526563fa798986f0467e"
   },
   "source": [
    "We see that the dataset (digits.data) is composed of 1797 samples, with 64 features, where each feature is a single image pixel. The images have been flattened to a 1-d vector of size (64,). Each sample in the dataset corrsponds to a 'target' in digits.target i.e. the 'answer'.\n",
    "\n",
    "Let's have a look at the first 4 images, stored in the images attribute of the dataset. If we were working from image files, we could load them using matplotlib.pyplot.imread. Note that each image must have the same size. For these images, we know which digit they represent: it is given in the 'target' of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "8b22fe850a1e1885fbb331fc198cc92a3805fd11"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAB4CAYAAADSWhi9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAACUtJREFUeJzt3V2MXVUZxvHnsRWJKXSmUS5AyLRygTHapiUkRCNtbCMGtSVaTITE1kibeCPRkPYCCSiJbYLaaqIZ/GoMatp60YYmRqlhqhBBWp0molHTdsTKR4R2hvIRpPb1Yp/KpNjZazr7fLyn/19Ccg7znr3WvMw8Z88+e7EcEQIA5PGmbk8AADA9BDcAJENwA0AyBDcAJENwA0AyBDcAJJMyuG3Psv2i7SuarAW9bSd62z7nW287EtytJp3+55TtVyY9v3m6x4uI/0TEnIh4ssnaJti+3fYztidsf8/2BW0e77zore2Ftn9p+3nbJ9s9XmvM86W3n7H9e9sv2D5q+6u2Z7V5zPOltzfb/ksrD561/UPbc2Z83E4vwLE9JumzEbF3iprZEdGRX84m2b5B0vclLZP0rKTdkvZFxB0dGn9M/dvbd0m6VtK4pB0RMbvD44+pf3v7OUkHJT0u6RJJeyTdHxH3dmj8MfVvb6+Q9HJEPGf7IknflfRURHxhJsftiUsltu+xvd32T22fkHSL7WttP2p73PbTtr9p+82t+tm2w/ZQ6/n9ra//3PYJ27+1PX+6ta2vf9j2X1vvkN+y/YjtNYXfyqcl3RcRf46IY5LukVT62rbol962evoDSX9qsD0z0ke9/XZEPBIR/46Io5J+Iul9zXVq+vqot09GxHOT/tUpSVfOtD89EdwtN6r6gZkrabukk5I+L+ltqn6Irpe0forXf0rSlyTNk/SkpK9Mt9b2JZJ2SLq9Ne4RSdecfpHt+a0fmkvPctx3qzpzOe2gpMtsz51iLp3QD73tVf3Y2w9IeqKwtp36ore2r7M9IekFSR+TtGWKeRTppeB+OCIeiIhTEfFKRDweEY9FxMmIOCzpPknXTfH6n0XE/oh4TdKPJS06h9qPSBqNiN2tr31D0v/eLSPiSEQMRMRTZznuHEkTk56ffnzRFHPphH7oba/qq97avlXSeyV9va62A/qitxGxLyLmSrpc0r2q3hhmpKPXCWv8Y/IT21dJ+pqkJZLeqmquj03x+mcmPX5ZVYhOt/bSyfOIiLB9tHbmr3tR0sWTnp9+fGIax2iHfuhtr+qb3tr+uKozzQ+2LvV1W9/0tvXao7b3qvor4pq6+qn00hn3mZ+SDkv6o6QrI+JiSXdKcpvn8LSkd5x+YtuSLpvG65+QtHDS84WS/hkRE2ep75R+6G2v6oveuvpg/TuSboiIXrhMIvVJb88wW9I7ZzqpXgruM12k6lLDS67uKJjqWlZT9khabPujtmerup729mm8/keSbrV9le1BSXdI2tb8NGcsXW9duVDSBa3nF7rNt1qeo4y9XaHqZ/fGiDjQpjk2IWNvb7F9eevxkKq/aH4100n1cnB/UdVdGidUvdNub/eAEfGspE+qur73vKp3xj9IelWSbC9wdZ/p//0gIiL2qLoG9mtJf5f0N0lfbve8z0G63rbqX1H1ge+s1uOeucNkkoy9vVPVB4C/8Ov3Uj/Q7nmfg4y9fY+kR22/JOlhVX+Vz/gNp+P3cWfiahHCU5I+ERG/6fZ8+gm9bR962z690ttePuPuCtvX2x6w/RZVtwe9Jul3XZ5WX6C37UNv26cXe0twv9H7JR2W9C9JH1J13e/V7k6pb9Db9qG37dNzveVSCQAkwxk3ACRDcANAMu1aOdnI9ZedO3fW1mzYsKG2ZsWKFUXjbdq0qbZmcHCw6FgFznXhQMeubS1durS2Znx8vOhYd999d23NypUri45VoOd7OzIyUluzatWqomMtWjTVSu7y8QrNZMFLI/3dvHlzbc3GjRtra+bPn19bI0kHDtTf2t7pXOCMGwCSIbgBIBmCGwCSIbgBIBmCGwCSIbgBIBmCGwCSIbgBIJle2rrsDUoW1xw5cqS25vjx40XjzZs3r7Zmx44dtTWrV68uGq/XDQwM1Nbs27ev6FgPPfRQbU2DC3C6anR0tLZm2bJltTVz55btMT02NlZUl0HJwpmS38Hh4eHamvXry/632CULcJYvX150rKZwxg0AyRDcAJAMwQ0AyRDcAJAMwQ0AyRDcAJAMwQ0AyRDcAJBM1xbglNzUXrK45tChQ7U1CxYsKJpTyU45JfPOsACnZJFIg7umFO3S0i927dpVW7Nw4cLamtIdcEp2F8pi3bp1tTUlC/OWLFlSW1O6A06nF9eU4IwbAJIhuAEgGYIbAJIhuAEgGYIbAJIhuAEgGYIbAJIhuAEgma4twCnZlWbx4sW1NaWLa0qU3LSfwZYtW2pr7rrrrtqaiYmJBmZTWbp0aWPH6nW33XZbbc3Q0FAjx5H6Z+cgqez3+fDhw7U1JYv3ShfWlGTV4OBg0bGawhk3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMj29AKdkR5om9eKN9ueiZOHGmjVramua/F7Hx8cbO1Y3lXwfJQugSnbJKbVt27bGjpVBySKdY8eO1daULsApqdu7d29tTZO/T5xxA0AyBDcAJENwA0AyBDcAJENwA0AyBDcAJENwA0AyBDcAJENwA0AyXVs5WbKK6MCBA42MVbIiUpL2799fW3PTTTfNdDrnpdHR0dqaRYsWdWAmM1Oy5dvWrVsbGat0deXAwEAj4/WTknwpWe0oSevXr6+t2bx5c23Npk2bisYrwRk3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMgQ3ACRDcANAMl1bgFOy/VDJgpidO3c2UlNqw4YNjR0L+ZRs+TYyMlJbc/DgwdqaVatWFcxIWrlyZW3N2rVrGzlOL9i4cWNtTcl2Y6UL8x588MHamk4vzOOMGwCSIbgBIBmCGwCSIbgBIBmCGwCSIbgBIBmCGwCSIbgBIJmeXoBTsqtEyYKYq6++umhOTe24k0HJriklCzJ2795dNF7JopSSxS3dVrJLT8luPyU1JbvtSGX/DYaGhmprsizAKdndZt26dY2NV7K4Znh4uLHxSnDGDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkAzBDQDJENwAkIwjottzAABMA2fcAJAMwQ0AyRDcAJAMwQ0AyRDcAJAMwQ0AyRDcAJAMwQ0AyRDcAJAMwQ0AyRDcAJAMwQ0AyRDcAJAMwQ0AyRDcAJAMwQ0AyRDcAJAMwQ0AyRDcAJAMwQ0AyRDcAJAMwQ0AyRDcAJDMfwFhTX+bEqVjSAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the data, which is just the images flattened into a 1-d array\n",
    "for i in range(0,4):\n",
    "    plt.subplot(2, 4,i + 1)\n",
    "    plt.axis('off')\n",
    "    imside = int(np.sqrt(digits.data[i].shape[0]))\n",
    "    im1 = np.reshape(digits.data[i],(imside,imside))\n",
    "    plt.imshow(im1, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: {}'.format(digits.target[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "6a99318882b81a988a7407aaa26982579dc5cb15"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#the images are also included in the dataset as digits.images\n",
    "for i in range(0,4):\n",
    "    plt.subplot(2, 4,i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(digits.images[i], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: {}'.format(digits.target[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "7777e27e86880f40da6418dd639bf843ee89a136"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from here we will be using the images. First we should flatten the images\n",
    "n_samples = len(digits.images)\n",
    "data_images = digits.images.reshape((n_samples, -1))\n",
    "data_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "f0587132c7a3de33eb2c4a98defc68ff54afdf5b"
   },
   "source": [
    "Before apply a classifier to the data, let's split the data into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "2d35177842db3296007ae707bdebae2a051c893e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data and target sizes: \n",
      "(1347, 64), (1347,)\n",
      "Test data and target sizes: \n",
      "(450, 64), (450,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_images,digits.target)\n",
    "print('Training data and target sizes: \\n{}, {}'.format(X_train.shape,y_train.shape))\n",
    "print('Test data and target sizes: \\n{}, {}'.format(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "a5445b8dfdedaaea745776291d05ad060ee73090"
   },
   "source": [
    "At this point we are ready to train a machine learning classifier on the training data. For this first attempt we will be using the support vector machine classifer. For a decription on SVM: http://docs.opencv.org/2.4/doc/tutorials/ml/introduction_to_svm/introduction_to_svm.html and http://www.robots.ox.ac.uk/~az/lectures/ml/lect2.pdf and https://www.analyticsvidhya.com/blog/2015/10/understaing-support-vector-machine-example-code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "5a166c0023171a16d02ef410189d1859d39fad19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "#fit to the trainin data\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "f4c7e7574c3a2a94c1450228c939f2f8d8ea336e"
   },
   "outputs": [],
   "source": [
    "# now to Now predict the value of the digit on the test data\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "6223c2b27449fe3fd9280db6d99cd227fe4e470c"
   },
   "source": [
    "Now to compare the predicted values against the expected values of the test dataset using sklearn metrics.classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "3d238eeb6dc34d444eaae3c238e77839c9aba1ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.93      1.00      0.97        43\n",
      "           2       1.00      1.00      1.00        46\n",
      "           3       1.00      0.98      0.99        45\n",
      "           4       1.00      1.00      1.00        38\n",
      "           5       1.00      0.96      0.98        46\n",
      "           6       0.98      1.00      0.99        46\n",
      "           7       0.98      1.00      0.99        44\n",
      "           8       0.96      0.94      0.95        54\n",
      "           9       0.98      0.96      0.97        45\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       450\n",
      "   macro avg       0.98      0.98      0.98       450\n",
      "weighted avg       0.98      0.98      0.98       450\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "9b1403cb7abc4585d44a09b5bb5bf8cd696a0c51"
   },
   "source": [
    "**precision** is the fraction of relevant instances among the retrieved instances and is defined as:\n",
    "\n",
    "precision = tp / (tp + fp)  or (true positives)/(prediced positives)\n",
    "\n",
    "**recall** is the fraction of relevant instances that have been retrieved over total relevant instances in the image, and is defined as \n",
    "\n",
    "recall = tp / (tp + fn) or (true positives)/(actual positives)\n",
    "\n",
    "Where, tp = true positives, fp = false positives anf fn = false negatives. Recall in this context is also referred to as the true positive rate or sensitivity, and precision is also referred to as positive predictive value (PPV). \n",
    "\n",
    "**f1-score**: is a measure of a test's accuracy. It considers both the precision and the recall to compute the score. The f1-score can be interpreted as a weighted average of the precision and recall, where an f1-score reaches its best value at 1 and worst at 0. \n",
    "\n",
    "The general formula is: 2.(precision.recall)/(precision+recall) \n",
    "\n",
    "The f1-score regulates bot precision and recall. \n",
    "\n",
    "References:\n",
    "https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "\n",
    "https://en.wikipedia.org/wiki/F1_score\n",
    "\n",
    "Lecture 11 of Andrew Ng's coursera course (week 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "ea4deeb1e8f6b3bf3bdce658cb7120efae0ae97d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[43  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 43  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 46  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 44  0  0  0  1  0  0]\n",
      " [ 0  0  0  0 38  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 44  1  0  0  1]\n",
      " [ 0  0  0  0  0  0 46  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 44  0  0]\n",
      " [ 0  3  0  0  0  0  0  0 51  0]\n",
      " [ 0  0  0  0  0  0  0  0  2 43]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "8ff5204a570e257a2cc7906ed776481c455b8f1d"
   },
   "source": [
    "The confuson matrix for only one class, e.g. 1 = detections 0 = non-detections\n",
    "\n",
    "<pre>\n",
    "         Actual Class\n",
    "         |  1 | 0  |\n",
    "         |----|----|\n",
    "Pred   1 | tp | fp |\n",
    "Class ---|----|----|\n",
    "       0 | fn | tn |\n",
    "\n",
    "</pre>\n",
    "\n",
    "Thus for 3 classes (1, 2, 3) it is e.g. 1 = cats, 2 = dogs, 3 = bears\n",
    "\n",
    "<pre>\n",
    "         Actual Class\n",
    "         |  1 | 2  | 3  |\n",
    "         |----|----|----|\n",
    "Pred   1 | tp | f1 | f1 |  where f1 = false \"1\", f2 = false \"2\" and f3 = false \"3\"\n",
    "Class ---|----|----|----|\n",
    "       2 | f2 | tp | f2 |\n",
    "      ---|----|----|----|\n",
    "       3 | f3 | f3 | tp |\n",
    "</pre>\n",
    "\n",
    "Thus the diagonal in the above matrix shows the number of true positives for each class, while the off-diagonals are the number of elements the particular class has been misclassified (false positives)??\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_execution_state": "idle",
    "_uuid": "6cb00bdc483c8a2267ff49e084f944b1af0010c7"
   },
   "source": [
    "**We have successfully trained our SVM classifier to detect handwritten images of digits. What next:**\n",
    "1. try different classifiers e.e. k-nearest neighbors, random forest, convolution neural networks \n",
    "2. apply to different image classification problems. See Kaggle or openML (https://www.openml.org/guide#!intro) for more datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
